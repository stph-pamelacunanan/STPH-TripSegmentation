{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45fe7aa2-9f09-424b-a86c-944d9055f98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: stph_trips: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir stph_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08766c60-8c09-48e8-b0c4-6ff91d14db1c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Trip Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac624366-c1de-41c7-9474-f5074198a344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stph_trips/trip_segmentor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stph_trips/trip_segmentor.py\n",
    "\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import os\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import math\n",
    "import folium\n",
    "import ast\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of Earth in kilometers (change to 3959 for miles)\n",
    "    \n",
    "    # Convert degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    \n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def txt_to_df(filename):\n",
    "    try:\n",
    "        # Open the file in read mode\n",
    "        with open(filename, 'r') as file:\n",
    "            # Read the contents of the file\n",
    "            contents = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    # Convert to a dataframe\n",
    "    ## Remove the BOM character if present\n",
    "    data = contents.lstrip('\\ufeff')\n",
    "    ## Use StringIO to simulate a file-like object\n",
    "    data_io = StringIO(data)\n",
    "    ## Read the data into a pandas DataFrame\n",
    "    df = pd.read_csv(data_io)\n",
    "    return df\n",
    "\n",
    "def interpolate_points(start, end, max_distance):\n",
    "    \"\"\"Generate intermediate points between two points if they are too far apart.\"\"\"\n",
    "    points = [start]  \n",
    "    start_coords = np.array(start)\n",
    "    end_coords = np.array(end)\n",
    "\n",
    "    total_distance = geodesic(start, end).meters\n",
    "    num_extra_points = int(np.floor(total_distance / max_distance))\n",
    "\n",
    "    if num_extra_points > 0:\n",
    "        for i in range(1, num_extra_points + 1):\n",
    "            ratio = i / (num_extra_points + 1)\n",
    "            interpolated_point = start_coords + ratio * (end_coords - start_coords)\n",
    "            points.append(tuple(interpolated_point))\n",
    "\n",
    "    points.append(end)  \n",
    "    return points\n",
    "\n",
    "def reduce_gps_points(df, lat_col, lon_col, min_distance=100, max_distance=150):\n",
    "    \"\"\"\n",
    "    Reduce GPS points such that:\n",
    "    - Any two retained points are at least `min_distance` meters apart.\n",
    "    - Intermediate points are inserted if two points are more than `max_distance` meters apart.\n",
    "\n",
    "    :param df: Pandas DataFrame containing latitude and longitude columns.\n",
    "    :param lat_col: Name of the latitude column.\n",
    "    :param lon_col: Name of the longitude column.\n",
    "    :param min_distance: Minimum distance (in meters) between retained points.\n",
    "    :param max_distance: Maximum distance (in meters) between retained points.\n",
    "    :return: Filtered Pandas DataFrame with all original columns.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    points = list(df.itertuples(index=False, name=None))\n",
    "    lat_idx = df.columns.get_loc(lat_col)\n",
    "    lon_idx = df.columns.get_loc(lon_col)\n",
    "\n",
    "    selected = [points[0]]  # Start with the first point\n",
    "    \n",
    "    for point in points[1:]:\n",
    "        lat_lon = (point[lat_idx], point[lon_idx])\n",
    "        last_selected = (selected[-1][lat_idx], selected[-1][lon_idx])\n",
    "\n",
    "        distance_to_last = geodesic(lat_lon, last_selected).meters\n",
    "\n",
    "        if distance_to_last >= max_distance:\n",
    "            # Insert intermediate points if the gap is too large\n",
    "            interpolated = interpolate_points(last_selected, lat_lon, max_distance)\n",
    "            selected.extend([(None, *pt) for pt in interpolated[1:-1]])\n",
    "\n",
    "        if distance_to_last >= min_distance:\n",
    "            selected.append(point)\n",
    "\n",
    "    # Final pass to ensure distance conditions are met\n",
    "    final_selected = [selected[0]]\n",
    "    for point in selected[1:]:\n",
    "        lat_lon = (point[lat_idx], point[lon_idx])\n",
    "        last_selected = (final_selected[-1][lat_idx], final_selected[-1][lon_idx])\n",
    "\n",
    "        distance_to_last = geodesic(lat_lon, last_selected).meters\n",
    "\n",
    "        if distance_to_last >= max_distance:\n",
    "            interpolated = interpolate_points(last_selected, lat_lon, max_distance)\n",
    "            final_selected.extend([(None, *pt) for pt in interpolated[1:-1]])\n",
    "\n",
    "        if distance_to_last >= min_distance:\n",
    "            final_selected.append(point)\n",
    "\n",
    "    # Convert selected points back to DataFrame\n",
    "    selected_df = pd.DataFrame(final_selected, columns=df.columns)\n",
    "\n",
    "    return selected_df\n",
    "\n",
    "def obtain_route_dict(path_of_gtfs_shapefiles, min_dist = 100, max_dist = 150):\n",
    "    txt_files = [file for file in os.listdir(path_of_gtfs_shapefiles) if file.endswith('.txt')]\n",
    "\n",
    "    # Initialize a dictionary in the form:\n",
    "    ## {'route_name': {'inbound': inbound_stops_df, 'outbound': outbound_stops_df}}\n",
    "    routes_dict = {}\n",
    "    \n",
    "    for txt_file in txt_files:\n",
    "        file_path = os.path.join(folder, txt_file)\n",
    "        \n",
    "        # Get the df\n",
    "        my_route = txt_to_df(file_path)\n",
    "        \n",
    "        # Outbound trip (shape_id = 1)\n",
    "        ## Refine the GTFS points of the outbound route\n",
    "        outbound_route = reduce_gps_points(my_route[my_route['shape_id'] == 1],\n",
    "                                           'shape_pt_lat', 'shape_pt_lon',\n",
    "                                           min_distance = min_dist, max_distance = max_dist)\n",
    "        ## Fix the sequencing of stops\n",
    "        outbound_route = outbound_route.reset_index().drop(columns = ['shape_pt_sequence']).rename(columns = {'index': 'stop_id'})\n",
    "        outbound_route['stop_id'] = outbound_route['stop_id'] + 1\n",
    "        outbound_route = outbound_route.rename(columns = {'shape_pt_lat': 'stop_lat', 'shape_pt_lon': 'stop_lon'})\n",
    "        ## Add a distance travelled column (in km)\n",
    "        outbound_route['prev_latitude'] = outbound_route['stop_lat'].shift(1)\n",
    "        outbound_route['prev_longitude'] = outbound_route['stop_lon'].shift(1)\n",
    "        outbound_route['kmTravelled'] = outbound_route.apply(lambda x: haversine(x['prev_latitude'], x['prev_longitude'],\n",
    "                                                                                 x['stop_lat'], x['stop_lon']), axis=1)\n",
    "        outbound_route['kmTravelled'] = outbound_route['kmTravelled'].fillna(0)\n",
    "        outbound_route = outbound_route.drop(columns = ['prev_latitude', 'prev_longitude', 'shape_id'])\n",
    "    \n",
    "        # Inbound trip (shape_id = 2)\n",
    "        ## Refine the GTFS points of the inbound route\n",
    "        inbound_route = reduce_gps_points(my_route[my_route['shape_id'] == 2],\n",
    "                                          'shape_pt_lat', 'shape_pt_lon',\n",
    "                                          min_distance = min_dist, max_distance = max_dist)\n",
    "        ## Fix the sequencing of stops\n",
    "        inbound_route = inbound_route.reset_index().drop(columns = ['shape_pt_sequence']).rename(columns = {'index': 'stop_id'})\n",
    "        inbound_route['stop_id'] = inbound_route['stop_id'] + 1\n",
    "        inbound_route = inbound_route.rename(columns = {'shape_pt_lat': 'stop_lat', 'shape_pt_lon': 'stop_lon'})\n",
    "        ## Add a distance travelled column (in km)\n",
    "        inbound_route['prev_latitude'] = inbound_route['stop_lat'].shift(1)\n",
    "        inbound_route['prev_longitude'] = inbound_route['stop_lon'].shift(1)\n",
    "        inbound_route['kmTravelled'] = inbound_route.apply(lambda x: haversine(x['prev_latitude'], x['prev_longitude'],\n",
    "                                                                               x['stop_lat'], x['stop_lon']), axis=1)\n",
    "        inbound_route['kmTravelled'] = inbound_route['kmTravelled'].fillna(0)\n",
    "        inbound_route = inbound_route.drop(columns = ['prev_latitude', 'prev_longitude', 'shape_id'])\n",
    "        \n",
    "        # Set the route name as the key\n",
    "        route_name = txt_file.removesuffix(\".txt\")\n",
    "        \n",
    "        # Append it in the dictionary `route_dict`\n",
    "        routes_dict[route_name] = {'outbound': outbound_route, 'inbound': inbound_route}\n",
    "\n",
    "    return routes_dict\n",
    "\n",
    "#######################################################################################################################################\n",
    "\n",
    "def route_gtfs_stops_mapper(df, latitude_name = 'latitude', longitude_name = 'longitude',\n",
    "                            output_html = \"custom_markers_map.html\"):\n",
    "    \"\"\"\n",
    "    Maps the coordinates from a DataFrame, connects them with a black line, \n",
    "    and customizes the markers for the first and last points.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with 'latitude' and 'longitude' columns.\n",
    "        output_html (str): File name for the output HTML.\n",
    "    \"\"\"\n",
    "    if latitude_name not in df.columns or longitude_name not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain the specified latitude and longitude column names.\")\n",
    "    \n",
    "    # Create a map centered at the first point\n",
    "    map_obj = folium.Map(location=[df[latitude_name][0], df[longitude_name][0]], zoom_start=18)\n",
    "\n",
    "    # Draw a black line connecting all the points\n",
    "    coordinates = list(zip(df[latitude_name], df[longitude_name]))\n",
    "    folium.PolyLine(\n",
    "        locations=coordinates,\n",
    "        color='black',  # Line color\n",
    "        weight=2,       # Line thickness\n",
    "    ).add_to(map_obj)\n",
    "\n",
    "    # Add CircleMarkers with custom colors for the first and last points\n",
    "    for i, (lat, lon) in enumerate(coordinates):\n",
    "        if i == 0:\n",
    "            color = 'green'  # First point\n",
    "        elif i == len(df) - 1:\n",
    "            color = 'red'  # Last point\n",
    "        else:\n",
    "            color = 'black'  # Other points\n",
    "\n",
    "        folium.CircleMarker(\n",
    "            location=(lat, lon),\n",
    "            radius=2.5,  # Control the size of the circle\n",
    "            color=color,  # Circle border color\n",
    "            fill=True,\n",
    "            fill_color=color,  # Circle fill color\n",
    "            fill_opacity=1.0,  # Opacity of the fill\n",
    "        ).add_to(map_obj)\n",
    "\n",
    "    # Save the map as an HTML file\n",
    "    map_obj.save(output_html)\n",
    "    print(f\"Map saved as {output_html}\")\n",
    "\n",
    "#######################################################################################################################################\n",
    "\n",
    "def nearest_stop_checker(vehicle_feeds_df, routes_dict, trip_type, dist_cutoff = 50):\n",
    "    \"\"\"\n",
    "    Finds the nearest stop for each GPS point in vehicle_feeds_df within a 50-meter radius\n",
    "    and returns the original DataFrame with an added 'stop_id' column.\n",
    "\n",
    "    :param vehicle_feeds_df: DataFrame with columns [\"latitude\", \"longitude\"] (vehicle positions).\n",
    "    :param trip_type: string, either 'inbound' or 'outbound'\n",
    "    :return: Original vehicle_feeds_df with an added 'stop_id' column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtain the `route_stops_df`\n",
    "    route_id = vehicle_feeds_df['route'].values[0]\n",
    "    route_stops_df = routes_dict[route_id][trip_type]\n",
    "    \n",
    "    # Convert stop coordinates into a fast lookup structure (KDTree)\n",
    "    stop_coords = route_stops_df[[\"stop_lat\", \"stop_lon\"]].to_numpy()\n",
    "    stop_tree = cKDTree(stop_coords)   ## Efficient spatial search structure\n",
    "    \n",
    "    # Convert vehicle coordinates to numpy array\n",
    "    vehicle_coords = vehicle_feeds_df[[\"latitude\", \"longitude\"]].to_numpy()\n",
    "    \n",
    "    # Query KDTree for the nearest stop for each vehicle point\n",
    "    distances, indices = stop_tree.query(vehicle_coords, k=1)   ## Get closest stop index\n",
    "    \n",
    "    # Compute geodesic distances to verify it's within 50 meters\n",
    "    closest_stops = []\n",
    "    for i, (vehicle_point, stop_idx) in enumerate(zip(vehicle_coords, indices)):\n",
    "        stop_point = stop_coords[stop_idx]\n",
    "        distance = geodesic(vehicle_point, stop_point).meters   ## Compute distance\n",
    "        \n",
    "        if distance <= dist_cutoff:\n",
    "            closest_stops.append(route_stops_df.iloc[stop_idx][\"stop_id\"])\n",
    "        else:\n",
    "            closest_stops.append(0)   ## No stop within range\n",
    "    \n",
    "    # Append stop_id column to the original DataFrame\n",
    "    vehicle_feeds_df = vehicle_feeds_df.copy()\n",
    "    vehicle_feeds_df[\"stop_id\"] = closest_stops\n",
    "\n",
    "    # Assign NA to \"stop_id\" if the \"identifier\" column is non-NA\n",
    "    vehicle_feeds_df.loc[vehicle_feeds_df['identifier'] != '', 'stop_id'] = np.nan\n",
    "    \n",
    "    return vehicle_feeds_df[['imei', 'timestamp', 'latitude', 'longitude', 'distanceTravelled',\n",
    "                             'stop_id', 'route', 'identifier']]\n",
    "\n",
    "def sequence_checker(df, trip_type, zero_cutoff = 60):\n",
    "    \"\"\"\n",
    "    Groups stop_id sequences that are non-decreasing and assigns a trip identifier.\n",
    "    Stops counting when encountering NaN in stop_id and does not start new sequences with NaN.\n",
    "\n",
    "    :param df: DataFrame with columns [\"timestamp\", \"latitude\", \"longitude\", \"stop_id\"]\n",
    "    :param trip_type: string, either 'inbound' or 'outbound'\n",
    "    :param zero_cutoff: Number of consecutive zeros to stop the trip sequence. 60 to represent 60 secs or 1 min.\n",
    "    :return: DataFrame with an additional \"identifier\" column.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    current_identifier = None\n",
    "    start_timestamp = None\n",
    "    last_stop_id = 0\n",
    "    zero_count = 0\n",
    "    in_sequence = False\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        stop_id = row[\"stop_id\"]\n",
    "        \n",
    "        # Stop sequence if stop_id is NaN\n",
    "        if pd.isna(stop_id):\n",
    "            in_sequence = False\n",
    "            current_identifier = None\n",
    "            zero_count = 0  # Reset zero counter\n",
    "            continue\n",
    "        \n",
    "        # If stop_id is zero, count consecutive zeros\n",
    "        if stop_id == 0:\n",
    "            zero_count += 1\n",
    "            if zero_count > zero_cutoff and in_sequence:\n",
    "                in_sequence = False  # Stop sequence\n",
    "                current_identifier = None\n",
    "            continue\n",
    "        else:\n",
    "            zero_count = 0  # Reset zero counter if stop_id is nonzero\n",
    "\n",
    "        # Start a new sequence if:\n",
    "        # 1. We are not in a sequence\n",
    "        # 2. stop_id is nonzero and NOT NaN\n",
    "        if not in_sequence and (stop_id > 0  and pd.notna(stop_id)):\n",
    "            start_timestamp = row[\"timestamp\"]\n",
    "            current_identifier = f\"{trip_type}_trip_{start_timestamp.strftime('%Y%m%d_%H%M%S')}\"\n",
    "            in_sequence = True\n",
    "\n",
    "        # If we are in a sequence, ensure non-decreasing stop_id\n",
    "        if in_sequence:\n",
    "            if stop_id < last_stop_id:  # If stop_id decreases, stop the sequence\n",
    "                in_sequence = False\n",
    "                current_identifier = None\n",
    "            else:\n",
    "                df.at[i, \"identifier\"] = current_identifier  # Assign trip ID\n",
    "\n",
    "        last_stop_id = stop_id  # Update last stop_id\n",
    "\n",
    "    return df\n",
    "\n",
    "def trip_validator(trips, trip_type, routes_dict, dist_threshold = 0.7, time_threshold = 15):\n",
    "    \n",
    "    # Get the expected distance from the trip_type and route\n",
    "    route_id = trips['route'].values[0]\n",
    "    route_stops_df = routes_dict[route_id][trip_type]\n",
    "    expected_dist = float(route_stops_df['kmTravelled'].sum())   \n",
    "    \n",
    "    # Obtain valid entries\n",
    "    trip_summary = trips[trips['identifier'] != ''].groupby('identifier').agg(\n",
    "        start_time = ('timestamp', 'min'),\n",
    "        time_diff = ('timestamp', lambda x: (x.max() - x.min()).total_seconds() / 60),\n",
    "        distance = ('distanceTravelled', 'sum'))\n",
    "    trip_summary = trip_summary.reset_index()\n",
    "    valid_trips = trip_summary[(trip_summary['time_diff'] > time_threshold) & \\\n",
    "                    (trip_summary['distance'] >= (dist_threshold * expected_dist))].reset_index(drop=True)\n",
    "\n",
    "    # Return the identifiers of the valid trips\n",
    "    return valid_trips['identifier'].values.tolist()\n",
    "\n",
    "def cut_trips_determinant(trips, trip_type, routes_dict, dist_threshold = 0.7):\n",
    "    \n",
    "    # Get the expected distance from the trip_type and route\n",
    "    route_id = trips['route'].values[0]\n",
    "    route_stops_df = routes_dict[route_id][trip_type]\n",
    "    expected_dist = float(route_stops_df['kmTravelled'].sum())   \n",
    "    \n",
    "    # Obtain cut trips\n",
    "    trip_summary = trips[trips['identifier'] != ''].groupby('identifier').agg(\n",
    "        start_time = ('timestamp', 'min'),\n",
    "        time_diff = ('timestamp', lambda x: (x.max() - x.min()).total_seconds() / 60),\n",
    "        distance = ('distanceTravelled', 'sum'))\n",
    "    trip_summary = trip_summary.reset_index()\n",
    "    cut_trips = trip_summary[(trip_summary['distance'] >= 1) & \\\n",
    "                    (trip_summary['distance'] < (dist_threshold * expected_dist))].reset_index(drop=True)\n",
    "\n",
    "    # Return the identifiers of the cut trips\n",
    "    return cut_trips['identifier'].values.tolist()\n",
    "\n",
    "def trip_segmentation(vehicle_feeds_df, routes_dict, my_dist_cutoff, zero_cutoff, my_dist_threshold, my_time_threshold):\n",
    "    \n",
    "    # Step 1\n",
    "    vehicle_feeds = vehicle_feeds_df.copy()\n",
    "    vehicle_feeds_engineOn = vehicle_feeds[vehicle_feeds['engineRpm'] > 0].reset_index(drop=True)\n",
    "    vehicle_feeds_engineOn['identifier'] = ''   ## Initialize an empty \"identifier\" column (similar to a trip_id)\n",
    "    vehicle_feeds_engineOn = vehicle_feeds_engineOn.sort_values(by = ['timestamp'])   ## Ensure data is in chronological order\n",
    "\n",
    "    ################################## ------------ OUTBOUND TRIPS ------------ ##################################\n",
    "    \n",
    "    # Step 2\n",
    "    outbound = nearest_stop_checker(vehicle_feeds_df = vehicle_feeds_engineOn,\n",
    "                                    routes_dict = routes_dict, \n",
    "                                    trip_type = 'outbound', dist_cutoff = my_dist_cutoff)\n",
    "\n",
    "    # Step 3\n",
    "    outbound_trips = sequence_checker(outbound, trip_type = 'outbound')\n",
    "\n",
    "    # Step 4\n",
    "    outbound_completeTrips_identifiers = trip_validator(outbound_trips, trip_type = 'outbound',\n",
    "                                                        routes_dict = routes_dict, \n",
    "                                                        dist_threshold = my_dist_threshold, time_threshold = my_time_threshold)\n",
    "\n",
    "    # Step 5\n",
    "    outbound_cutTrips_identifiers = cut_trips_determinant(outbound_trips, trip_type = 'outbound',\n",
    "                                                          routes_dict = routes_dict, \n",
    "                                                          dist_threshold = my_dist_threshold)\n",
    "\n",
    "    # Step 6\n",
    "    outbound_completeTrips = outbound_trips.loc[outbound_trips['identifier'].isin(outbound_completeTrips_identifiers),\n",
    "                                                ['imei', 'timestamp', 'longitude', 'latitude',\n",
    "                                                 'identifier']].reset_index(drop=True)\n",
    "    outbound_cutTrips = outbound_trips.loc[outbound_trips['identifier'].isin(outbound_cutTrips_identifiers),\n",
    "                                            ['imei', 'timestamp', 'longitude', 'latitude',\n",
    "                                             'identifier']].reset_index(drop=True)\n",
    "    outbound_cutTrips['identifier'] = outbound_cutTrips['identifier'].str.replace(\"trip\", \"cuttrip\", regex=False)\n",
    "    \n",
    "    outbound_trips = pd.concat([outbound_completeTrips, outbound_cutTrips], ignore_index=True)\n",
    "    vehicle_feeds_engineOn = vehicle_feeds_engineOn.drop(columns = ['identifier'])\n",
    "    vehicle_feeds_engineOn = vehicle_feeds_engineOn.merge(outbound_trips,\n",
    "                                                          on = ['imei', 'timestamp', 'longitude', 'latitude'],\n",
    "                                                          how = 'left')\n",
    "    vehicle_feeds_engineOn['identifier'] = vehicle_feeds_engineOn['identifier'].fillna('')\n",
    "\n",
    "    ################################## ------------ INBOUND TRIPS ------------ ##################################\n",
    "\n",
    "    # Step 2\n",
    "    inbound = nearest_stop_checker(vehicle_feeds_df = vehicle_feeds_engineOn,\n",
    "                                   routes_dict = routes_dict, \n",
    "                                   trip_type = 'inbound', dist_cutoff = my_dist_cutoff)\n",
    "\n",
    "    # Step 3\n",
    "    inbound_trips = sequence_checker(inbound, trip_type = 'inbound')\n",
    "\n",
    "    # Step 4\n",
    "    inbound_completeTrips_identifiers = trip_validator(inbound_trips, trip_type = 'inbound',\n",
    "                                                       routes_dict = routes_dict, \n",
    "                                                       dist_threshold = my_dist_threshold, time_threshold = my_time_threshold)\n",
    "\n",
    "    # Step 5\n",
    "    inbound_cutTrips_identifiers = cut_trips_determinant(inbound_trips, trip_type = 'inbound',\n",
    "                                                         routes_dict = routes_dict, \n",
    "                                                         dist_threshold = my_dist_threshold)\n",
    "\n",
    "    # Step 6\n",
    "    inbound_completeTrips = inbound_trips.loc[inbound_trips['identifier'].isin(inbound_completeTrips_identifiers),\n",
    "                                              ['imei', 'timestamp', 'longitude', 'latitude',\n",
    "                                               'identifier']].reset_index(drop=True)\n",
    "    inbound_cutTrips = inbound_trips.loc[inbound_trips['identifier'].isin(inbound_cutTrips_identifiers),\n",
    "                                         ['imei', 'timestamp', 'longitude', 'latitude',\n",
    "                                          'identifier']].reset_index(drop=True)\n",
    "    inbound_cutTrips['identifier'] = inbound_cutTrips['identifier'].str.replace(\"trip\", \"cuttrip\", regex=False)\n",
    "    \n",
    "    inbound_trips = pd.concat([inbound_completeTrips, inbound_cutTrips], ignore_index=True)\n",
    "\n",
    "    vehicle_feeds_engineOn = vehicle_feeds_engineOn.merge(inbound_trips,\n",
    "                                                          on = ['imei', 'timestamp', 'longitude', 'latitude'],\n",
    "                                                          how = 'left', \n",
    "                                                          suffixes = (\"_outbound\", \"_inbound\"))\n",
    "    # Fix the identifier column (it has been doubled)\n",
    "    vehicle_feeds_engineOn[\"trip_identifier\"] = np.where(vehicle_feeds_engineOn[\"identifier_outbound\"] == \"\",\n",
    "                                           vehicle_feeds_engineOn[\"identifier_inbound\"],\n",
    "                                           vehicle_feeds_engineOn[\"identifier_outbound\"])\n",
    "    vehicle_feeds_engineOn = vehicle_feeds_engineOn.drop(columns = ['identifier_outbound', 'identifier_inbound'])\n",
    "\n",
    "    # Return only the vehicle feeds with identified trip\n",
    "    return vehicle_feeds_engineOn[(vehicle_feeds_engineOn['trip_identifier'] != '') & \\\n",
    "                                  (vehicle_feeds_engineOn['trip_identifier'].notna())].sort_values( \\\n",
    "                                        by = ['deviceCode', 'timestamp']).reset_index(drop = True)\n",
    "\n",
    "def tripSummarizer(vehicle_feeds_with_trip_id):\n",
    "    return vehicle_feeds_with_trip_id.groupby('trip_identifier').agg(\n",
    "        start_time = ('timestamp', 'min'),\n",
    "        time_diff = ('timestamp', lambda x: (x.max() - x.min()).total_seconds() / 60),\n",
    "        distance = ('distanceTravelled', 'sum')).reset_index().sort_values(by = ['trip_identifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8296916-8250-44aa-932c-fe62c48ab01c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Trip Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7fd300-e12a-4d06-bafa-6e99009bcd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stph_trips/trip_summary.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stph_trips/trip_summary.py\n",
    "\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import ast\n",
    "\n",
    "#######################################################################################################################################\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of Earth in kilometers (change to 3959 for miles)\n",
    "    \n",
    "    # Convert degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    \n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def get_overwaiting_durations(df, max_speed = 5, min_duration = 90):\n",
    "    # Ensure that the timestamp is in the correct datetime format\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Add a column that indicates whether the vehicle is moving slowly (at least 5 kph)\n",
    "    df['is_overwaiting'] = df['vehicleSpeedInKph'] <= max_speed\n",
    "    \n",
    "    # List to store durations of overwaiting events\n",
    "    overwaiting_durations = []\n",
    "    start_time = None\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        # Check for start of a new overwaiting period\n",
    "        if df['is_overwaiting'].iloc[i] and not df['is_overwaiting'].iloc[i-1]:\n",
    "            start_time = df['timestamp'].iloc[i]\n",
    "        \n",
    "        # If we are in an overwaiting period and the condition is no longer met, check duration\n",
    "        if not df['is_overwaiting'].iloc[i] and df['is_overwaiting'].iloc[i-1]:\n",
    "            if start_time is not None:\n",
    "                duration = (df['timestamp'].iloc[i] - start_time).total_seconds()\n",
    "                if duration >= min_duration:\n",
    "                    overwaiting_durations.append(duration)\n",
    "                start_time = None\n",
    "    \n",
    "    # Check if the last segment of data ended with an overwaiting event\n",
    "    if df['is_overwaiting'].iloc[-1]:\n",
    "        duration = (df['timestamp'].iloc[-1] - start_time).total_seconds()\n",
    "        if duration >= min_duration:\n",
    "            overwaiting_durations.append(duration)\n",
    "    \n",
    "    return overwaiting_durations\n",
    "\n",
    "def get_harsh_acceleration(my_df, tuple_thresholds):\n",
    "    df = my_df.copy()\n",
    "\n",
    "    # Get the cutoffs\n",
    "    acceleration = tuple_thresholds[0]\n",
    "    rpm = tuple_thresholds[1]\n",
    "\n",
    "    # Ensure that the timestamp is in the correct datetime format\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "    # Compute time difference in seconds\n",
    "    df['time_diff'] = df['timestamp'].diff().dt.total_seconds()\n",
    "    \n",
    "    # Compute speed difference (convert kph to m/s)\n",
    "    df['speed_mps'] = df['vehicleSpeedInKph'] * (1000 / 3600)  # Convert kph to m/s\n",
    "    df['speed_diff'] = df['speed_mps'].diff()\n",
    "    \n",
    "    # Compute acceleration (m/s^2)\n",
    "    df['acceleration'] = df['speed_diff'] / df['time_diff']\n",
    "    \n",
    "    # Handle potential division by zero or NaN values\n",
    "    df['acceleration'] = df['acceleration'].fillna(0)\n",
    "    df['time_diff'] = df['time_diff'].replace(0, np.nan)\n",
    "    \n",
    "    # Determine reckless behavior\n",
    "    reckless = (df['acceleration'] > acceleration) & (df['engineRpm'] > rpm)\n",
    "    \n",
    "    return reckless.tolist()\n",
    "\n",
    "def get_harsh_braking(my_df, tuple_thresholds):\n",
    "    df = my_df.copy()\n",
    "\n",
    "    # Get the cutoffs\n",
    "    decceleration = tuple_thresholds[0]\n",
    "    rpm_drop = tuple_thresholds[1]\n",
    "\n",
    "    # Ensure that the timestamp is in the correct datetime format\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "    # Compute time difference in seconds\n",
    "    df['time_diff'] = df['timestamp'].diff().dt.total_seconds()\n",
    "    \n",
    "    # Compute speed difference (convert kph to m/s)\n",
    "    df['speed_mps'] = df['vehicleSpeedInKph'] * (1000 / 3600)  # Convert kph to m/s\n",
    "    df['speed_diff'] = df['speed_mps'].diff()\n",
    "    \n",
    "    # Compute acceleration (m/s^2)\n",
    "    df['acceleration'] = df['speed_diff'] / df['time_diff']\n",
    "    \n",
    "    # Handle potential division by zero or NaN values\n",
    "    df['acceleration'] = df['acceleration'].fillna(0)\n",
    "    df['time_diff'] = df['time_diff'].replace(0, np.nan)\n",
    "\n",
    "    # Compute rpm difference\n",
    "    df['rpmChange'] = df['engineRpm'].diff()\n",
    "    \n",
    "    # Determine reckless behavior\n",
    "    braking = (df['acceleration'] < decceleration) & (df['rpmChange'] < rpm_drop)\n",
    "    \n",
    "    return braking.tolist()\n",
    "\n",
    "def get_overspeeding_duration(df: pd.DataFrame, overspeeding: float, maxOverspeed: float = None) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the number of seconds the vehicle was overspeeding.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with 'speedInKph' and 'timestamp' columns.\n",
    "    overspeeding (float): Overspeeding threshold in kph.\n",
    "    maxOverspeed (float, optional): Maximum speed limit to consider for overspeeding duration.\n",
    "    \n",
    "    Returns:\n",
    "    float: Total duration in seconds the vehicle was overspeeding.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['time_diff'] = df['timestamp'].diff().dt.total_seconds()\n",
    "    \n",
    "    if maxOverspeed is not None:\n",
    "        overspeeding_duration = df.loc[(df['vehicleSpeedInKph'] > overspeeding) & (df['vehicleSpeedInKph'] <= maxOverspeed), 'time_diff'].sum()\n",
    "    else:\n",
    "        overspeeding_duration = df.loc[df['vehicleSpeedInKph'] > overspeeding, 'time_diff'].sum()\n",
    "    \n",
    "    return overspeeding_duration if not np.isnan(overspeeding_duration) else 0\n",
    "\n",
    "def compute_missing_data_proportion(df):\n",
    "    # Ensure that the timestamp is in the correct datetime format\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Get the earliest and latest timestamps in the dataset\n",
    "    start_time = df['timestamp'].min()\n",
    "    end_time = df['timestamp'].max()\n",
    "    \n",
    "    # Create a sequence of all expected timestamps (1 second intervals)\n",
    "    expected_timestamps = pd.date_range(start=start_time, end=end_time, freq='1s')\n",
    "    \n",
    "    # Get the set of actual timestamps from the dataset\n",
    "    actual_timestamps = set(df['timestamp'])\n",
    "    \n",
    "    # Count the missing timestamps\n",
    "    missing_timestamps = expected_timestamps.difference(actual_timestamps)\n",
    "    \n",
    "    # Calculate the total number of expected timestamps\n",
    "    total_seconds = len(expected_timestamps)\n",
    "    \n",
    "    # Proportion of missing data\n",
    "    missing_proportion = len(missing_timestamps) / total_seconds\n",
    "    \n",
    "    return round(missing_proportion,2)\n",
    "\n",
    "#######################################################################################################################################\n",
    "\n",
    "def trip_super_summary(vehicle_feeds_with_tripID, speed_cutoff = 5,\n",
    "                       overwaiting_time = [90, 150],\n",
    "                       overspeeding_thresholds = [60, 65],\n",
    "                       harsh_acceleration = [(2.5, 2000), (2.5, 2000), (3.5, 2000), (3.5, 2500)],\n",
    "                       harsh_braking = [(-2.5, -1000), (-3.5, -1000)]):\n",
    "    \"\"\"\n",
    "    vehicle_feeds_with_tripID: pd.DataFrame that is a result of the trip_segmentation() function (i.e., feeds from a single vehicle)\n",
    "    \"\"\"\n",
    "    \n",
    "    my_trips_summary = pd.DataFrame()\n",
    "\n",
    "    # Breakdown the df into one df per trip, saved in a list\n",
    "    list_of_trips = []\n",
    "    for trip_id in vehicle_feeds_with_tripID['trip_identifier'].unique().tolist():\n",
    "        df = vehicle_feeds_with_tripID[vehicle_feeds_with_tripID['trip_identifier'] == trip_id]\n",
    "        ## Ensure df is ordered chronologically\n",
    "        df = df.sort_values(by = 'timestamp').reset_index(drop=True)\n",
    "        list_of_trips.append(df)\n",
    "    \n",
    "    for df in list_of_trips:\n",
    "        \n",
    "        # Add fuel consumed per row\n",
    "        df['fuelRatePerSec'] = df['engineFuelRate'] / 3600\n",
    "        df['time_diff'] = df['timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "        df['fuelConsumed'] = df['fuelRatePerSec'] * df['time_diff']  # Total liters consumed\n",
    "        \n",
    "        # Add distance travelled per row\n",
    "        df['prev_latitude'] = df['latitude'].shift(1)\n",
    "        df['prev_longitude'] = df['longitude'].shift(1)\n",
    "        df['distanceTravelled'] = df.apply(lambda x: haversine(x['prev_latitude'], x['prev_longitude'],\n",
    "                                                               x['latitude'], x['longitude']), axis=1)\n",
    "        df['distanceTravelled'] = df['distanceTravelled'].fillna(0)\n",
    "        \n",
    "        # Compute the stats\n",
    "        last_row = len(df)-1\n",
    "        ## Metadata\n",
    "        imei = df['imei'].values[0]\n",
    "        route = df['route'].values[0]\n",
    "        trip_type = df['trip_identifier'].str.split(\"_\").str[0].str.capitalize().values[0]\n",
    "        trip_type2 = df['trip_identifier'].str.split(\"_\").str[1].str.capitalize().values[0]\n",
    "        if trip_type2 == 'Trip':\n",
    "            trip_status = 'Complete trip'\n",
    "        else:\n",
    "            trip_status = 'Cut trip'\n",
    "        date = df['timestamp'].dt.strftime(\"%b %d, %Y\")[0]\n",
    "        start = df['timestamp'].dt.strftime(\"%I:%M %p\")[0]\n",
    "        end = df['timestamp'].dt.strftime(\"%I:%M %p\")[last_row]\n",
    "        ## Stats\n",
    "        duration = (df['timestamp'][last_row] - df['timestamp'][0]).total_seconds() / 60\n",
    "        ave_speed = df['vehicleSpeedInKph'].mean()\n",
    "        max_speed = df['vehicleSpeedInKph'].max()\n",
    "        fuel_consumed = df['fuelConsumed'].sum()\n",
    "        distance_travelled = df['distanceTravelled'].sum()\n",
    "        missing_data = compute_missing_data_proportion(df)\n",
    "        \n",
    "        # Append to the dataframe\n",
    "        new_row = pd.DataFrame(data = {'Vehicle ID': [imei],\n",
    "                                       'Route': [route],\n",
    "                                       'Trip type': [trip_type],\n",
    "                                       'Trip status': [trip_status],\n",
    "                                       'Date': [date],\n",
    "                                       'Start time': [start], 'End time': [end],\n",
    "                                       'Total trip duration (min)': [round(duration,2)],\n",
    "                                       'Average speed (kph)': [float(round(ave_speed, 2))],\n",
    "                                       'Maximum speed (kph)': [float(round(max_speed, 2))],\n",
    "                                       'Total distance travelled (km)': [float(round(distance_travelled, 2))],\n",
    "                                       'Total fuel consumed (L)': [float(round(fuel_consumed, 2))],\n",
    "                                       'Missing data (%)': [missing_data * 100]})\n",
    "\n",
    "        # For criteria with several thresholds\n",
    "        \n",
    "        ## Overwaiting\n",
    "        for overwaiting_threshold in overwaiting_time:\n",
    "            overwaiting = get_overwaiting_durations(df, max_speed = speed_cutoff, min_duration = overwaiting_threshold)\n",
    "            overwaiting_events = len(overwaiting)\n",
    "            if overwaiting_events>0:\n",
    "                ave_overwaiting_duration = float(round(np.mean(overwaiting)))\n",
    "            else:\n",
    "                ave_overwaiting_duration = 0\n",
    "            colname1 = 'Total overwaiting events (' + str(overwaiting_threshold) + ')'\n",
    "            new_row[colname1] = overwaiting_events\n",
    "            colname2 = 'Average overwaiting time (' + str(overwaiting_threshold) + ')'\n",
    "            new_row[colname2] = ave_overwaiting_duration\n",
    "\n",
    "        ## Harsh acceleration\n",
    "        for acceleration_tuple in harsh_acceleration:\n",
    "            harsh_acceleration_result = get_harsh_acceleration(df, acceleration_tuple)\n",
    "            colname3 = 'Total harsh acceleration events ' + str(acceleration_tuple)\n",
    "            new_row[colname3] = sum(harsh_acceleration_result)\n",
    "        \n",
    "        ## Harsh braking\n",
    "        for braking_tuple in harsh_braking:\n",
    "            harsh_braking_result = get_harsh_braking(df, braking_tuple)\n",
    "            colname4 = 'Total harsh braking events ' + str(braking_tuple)\n",
    "            new_row[colname4] = sum(harsh_braking_result)\n",
    "\n",
    "        ## Overspeeding\n",
    "        if len(overspeeding_thresholds) > 1:\n",
    "            for i in range(len(overspeeding_thresholds)): \n",
    "                overspeed = overspeeding_thresholds[i]\n",
    "                if i+1 != len(overspeeding_thresholds):\n",
    "                    next_overspeed = overspeeding_thresholds[i+1]\n",
    "                    overspeeding_duration = get_overspeeding_duration(df, overspeed, next_overspeed)\n",
    "                    colname5 = 'Total overspeeding duration (' + str(overspeed) + '-' + str(next_overspeed) + ' kph)'\n",
    "                    new_row[colname5] = overspeeding_duration\n",
    "                else:\n",
    "                    overspeeding_duration = get_overspeeding_duration(df, overspeed)\n",
    "                    colname5 = 'Total overspeeding duration (' + str(overspeed) + ' kph)'\n",
    "                    new_row[colname5] = overspeeding_duration\n",
    "        else:\n",
    "            for overspeed in overspeeding_thresholds: \n",
    "                overspeeding_duration = get_overspeeding_duration(df, overspeed)\n",
    "                colname5 = 'Total overspeeding duration (' + str(overspeed) + ' kph)'\n",
    "                new_row[colname5] = overspeeding_duration\n",
    "\n",
    "        # Add to the main dataframe result\n",
    "        my_trips_summary = pd.concat([my_trips_summary, new_row], ignore_index=True)\n",
    "        \n",
    "    # Return the trip super summaries table\n",
    "    return my_trips_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f1d58b-2d2d-47cc-8ec6-c06b4a123056",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating the local library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62297156-2e02-4d35-8307-0c1f15d2a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stph_trips/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stph_trips/__init__.py\n",
    "\n",
    "from .trip_segmentor import obtain_route_dict, reduce_gps_points, route_gtfs_stops_mapper, trip_segmentation\n",
    "from .trip_summary import haversine, trip_super_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f0710-cb6c-49c9-9913-a41b596ace55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8617017-44e2-4210-a0b6-367be08cfb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
